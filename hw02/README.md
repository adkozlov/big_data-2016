## Легенда
Ваш сервис хранит большое количество документов. С документами работают
пользователи, которые в свою очередь разбиты на несколько команд.
С каждым документом могут работать несколько пользователей, не обязательно состоящих
в одной и той же команде.

Вы хотите найти документы, с которыми работают пользователи из разных команд и
вывести идентификаторы таких документов, пользователей и команд, в которых они состоят.

## Подробности о задаче

У вас в файловой системе расположено какое-то количество файлов, именуемых далее _шардами_, содержащих вашу базу данных в формате JSON. В каждом шарде содержится либо список
пользователей, состоящих в одной команде (не более одной команды в шарде), либо массив записей о документах и работающих с ними пользователях (произвольное количество записей).

Примеры шардов со списком пользователей:

__shard1__

```
{
  "Team": "Dream Team",
  "Users": ["Happy Alice", "Awkward Bob", "Hungry Emma"]
}
```

__shard2__

```
{
  "Team": "Scream Team",
  "Users": ["Sad Cathy"]
}
```

Пример шарда с массивом документов:

__shard3__

```
[
  {
    "DocID": "12345",
    "Users": ["Sad Cathy", "Awkward Bob"]
  },
  {
    "DocID": "54321",
    "Users": ["Awkward Bob"]
  },
  {
    "DocID": "9999",
    "Users": ["Happy Alice", "Hungry Emma"]
  }
]  
```

Имена команд и идентификаторы документов глобально уникальны. Про пользователей ничего
наверняка неизвестно, за исключением того, что одинаковое имя означает одного и того же
пользователя.

Вам нужно написать _конвейер_ aka последовательность map-reduce'ов, которые в конечном итоге произведут один или более выходных шардов, содержащих JSON записи следующего вида:

```
[
  {
    "DocID": "12345"
    "Users": ["Sad Cathy", "Scream Team", "Awkward Bob", "Dream Team"]
  }
]
```

В массиве _Users_ должны быть записаны поочерёдно имя пользователя и название команды,
в которой он состоит.

Вышеприведённый пример является ответом для вышевышеприведённых примеров входных шардов.

Весь список имеющихся входных шардов дан в файле-каталоге, также расположенном в файловой
системе. В этом файле в каждой строке записан путь к файлу-шарду. Для удобства, можете считать,
что путь либо абсолютный, либо относительный к каталогу, в котором запускается map-reduce и лежит файл-каталог.


## Инфраструктура Map-Reduce

В каталогах `../mapreduce/{lin,win,mac}` находится бинарник `mapreduce`, скомпилированный для
каждой из этих трёх платформ. Этот бинарник умеет использовать в качестве реализаций
функций map и reduce скрипты на питоне. Инструкции по запуску процесса и пример wordcount находятся в каталоге `../mapreduce`

Вам нужно написать несколько файлов на питоне, реализующих конвейер. У вас, скорее всего, получится как минимум два map-reduce процесса.

Обратите внимание, что если вы подаете выход одного звена конвейера на вход другому, то для корректной работы инфраструктуры вам понадобится сгенерировать новый файл-каталог. содержащий в себе пути к новым шардам.

Дополнительно напишите, пожалуйста, скрипт на bash или python, который будет дирижировать процессом, запускать map-reduce'ы и генерировать файлы-каталоги. Предполагая, что вы работаете на Linux, скрипт-дирижер будет выглядеть примерно так:

```

# Запускаем первый шаг
../mapreduce/lin/mapreduce -shard-file shards.txt -mapper ./my_mapper1.py -reducer ./my_reducer1.py

# Генерируем список шардов
for f in $(ls my_reduce_out*.json); do echo $f; done >> step2_shards.txt

# Запускаем второй шаг
../mapreduce/lin/mapreduce -shard-file step2_shards.txt -mapper ./my_mapper2.py -reducer ./my_reducer2.py

```


## Тестовые данные

В каталоге `data` находятся тестовые данные очень маленького размера. Файл `shards.txt`
является для них файлом-каталогом.

## Ограничения и пожелания

Один шард поместится в память одного процесса. Все данные в память одного процесса не поместятся. Постарайтесь реализовать конвейер так, чтобы узких мест не было.

Попробуйте одновременно с построением ответа найти возможные несогласованности и ошибки в данных.
